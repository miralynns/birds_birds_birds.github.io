---
title: "Mine the Genome using Linux/Unix Command Line"
output:
#  bookdown::pdf_document2:
#    toc: TRUE
  bookdown::html_document2: 
    toc: TRUE
    toc_float: TRUE
    theme: cosmo
link-citations: yes
fontsize: 12pt
editor_options: 
  markdown: 
    wrap: sentence
---

**Now we are ready to mine the genome!**

In this section, each step is listed in the order you should proceed.
Examples of the slurm script dependencies and job steps explanations are provided, but be sure to include the shebang and resource request portions of the slurm file prior to submitting a job.

Some modules will take longer than others to run.
Examples of output files are also provided, so you can confirm necessary output files are resulting from each step.
Confirm each job has completed successfully before moving onto the next.
It is recommended to review files last edited time and sizing using `ls -lht`.

If a job fails to run or if the file sizes are empty or suspiciously low, review the log file using the `nano` or `less` command and troubleshoot accordingly.

# Trim Galore

TrimGalore is used to trim the Illumina adapters from the RNA-seq data.
Be sure to identify the file names of the RNA-seq data downloaded from the SRA Toolkit step.
Trim Galore is run using bioconda, so activating an environment was required for this module.

## Slurm script example

```         
# Sort path:
datapath=/scratch/username/tlr_mining/gyrfalcon/sra

# Module load
. ~/.bashrc  # this line sources your bashrc
conda activate trimgalore-env
trim_galore --paired --illumina SRR21639343_1.fastq SRR21639343_2.fastq
```

### Dependencies Explanation

```         
-- paired: identifies that they SRA files are paired end sequencing reads and the files are identified with the _1 and _2 at the end of the respective file names.
-- illumina: identifies that illumina sequencing adapters are present and will be trimmed from the reads.
```

#### Output files

Four files should appear in the sra directory when this process is complete:

-   Two **trimming_report.txt** files (one for each sra file)

-   A **val_1.fq** and **val_2.fq** file for each sra file, indicating they are the results of the adapter trimming process.

# Hisat 2

Run [hisat2 aligner](http://daehwankimlab.github.io/hisat2/) to align the adapter-trimmed RNA-seq data to the reference genome of the non-model species.

## Slurm script example

```         
# Load modules:

module load python/3.9.7
module load hisat2/2.2.1 
module load samtools/1.14

# Sort Paths:
HiSatSam=/scratch/username/tlr_mining/p_falcon/hisat2
RNAseq=/scratch/username/tlr_mining/p_falcon/sra
genome=/scratch/username/tlr_mining/p_falcon/genome

# Hisat 2:
hisat2-build -p 20 ${genome}/GCF_023634155.1_bFalPer1.pri_genomic.fna ${genome}/bFalPer1.pri /
hisat2 -q --phred33 --no-unal -p 20 -x ${genome}/bFalPer1.pri -1 ${RNAseq}/SRR13279135_1_val_1.fq -2 ${RNAseq}/SRR13279135_2_val_2.fq -S ${HiSatSam}/bFalPer1.pri_align.sam
```

### Dependencies Explanation

```         
- Phred33: quality threshold
- p: number of processors available 
- x: genome_name for the index that we just created 
- 1: read.1.fq read.2.fq (specify read files) 
- S: provide a name for an output file in *.sam format
```

#### Output file

In the Hisat2 directory, one file should appear as the result and indicated in the -S option dependencies.
This file should be in **.sam** format.

# Samtools

Three packages of [samtools](http://www.htslib.org/doc/samtools.html) are used to select the aligned reads we want to visualize on the reference.

-   **Samtools view** will keep only the reads that align well and align in their primary alignment position.

-   **Samtools sort** is used when further subsetting alignment reads by reads aligning by one particular contig or chromosome versus another.

-   **Samtools index** assists in downstream sub setting and calculating expression of the genes of interest.

## Slurm script example

```         
# Load modules:
module load python/3.9.7
module load samtools/1.14

# Sort paths:
HiSatSam=/scratch/username/tlr_mining/p_falcon/hisat_SAM
samtools=/scratch/username/tlr_mining/p_falcon/samtools

# Samtools:
samtools view -b -@ 20 -f 3 -F 256 -q 40 ${HiSatSam}/bFalPer1.pri_align.sam > ${samtools}/bFalPer1.pri_align.bam 
samtools sort -@ 16 ${samtools}/bFalPer1.pri_align.bam > ${samtools}/bFalPer1.pri_align_sorted.bam 
samtools index -b ${samtools}/bFalPer1.pri_align_sorted.bam
```

### Dependencies Explanation

```         
- b: adjust output format
- @: number of processors
- q: subsetting based on quality of alignmnet (40 is high quality map from read to genome)
- f: reads to include (3: both ends of paired end reads to map and on same scaffold)
- F: reads to exclude (256: not primary alignment - only keep primary alignment)
- output: bam file (binary alignment file required for Geneious)
```

#### Output Files

In the samtools directory, three files should appear as indicated in the output options from the slurm script.
Files should have the three following formats:

1.  align.bam

2.  align_sorted.bam

3.  align_sorted.bam.bai

# BLAST

[BLAST](https://www.metagenomics.wiki/tools/blast) is a software tool that allows users to search the [NCBI database](https://blast.ncbi.nlm.nih.gov/Blast.cgi) for similar nucleotide or protein sequences.
In this section, we will complete steps:

1.  Make a database of functional genes of interest from the reference genome of the non-model organism identified using the fasta file created of function genes of interest identified in the model organism.
    Completed using `makeblastdb`.

2.  Search translated nucleotide databases for the protein sequences of the function genes of interest.
    Completed using `tblastn`.

3.  Use the subsetted aligned reads from samtools with the database of matches identified from step 2 to identify which contigs of the reference genome of the model organism have the functional genes of interest.
    For this step we will run the processing in parallel using `rb-parrell`, which requires bioconda.

## BLAST slurm script example

```         
# Module load - Activate python environment
. ~/.bashrc
conda activate blast-env 
conda install -c conda-forge rb-parallel parallel

# Load Modules:
module load blast/2.11.0
module load samtools/1.14

# Sort Paths:
data=/scratch/username/tlr_mining/p_falcon/blast
genome=/scratch/username/tlr_mining/p_falcon/genome
bam=/scratch/username/tlr_mining/p_falcon/samtools

# Blast
makeblastdb -in ${genome}/GCF_023634155.1_bFalPer1.pri_genomic.fna -dbtype nucl -parse_seqids -out ${data}/bFalPer1.pri_genomeDB
tblastn -db ${data}/bFalPer1.pri_genomeDB -query ${data}/Zebra_Finch_TLRs.fasta -out ${data}/bFalPer1.pri_TLR_blastn.out -outfmt 6 -num_threads 7 -evalue 0.000001

cut -f2 ${data}/bFalPer1.pri_TLR_blastn.out | sort | uniq > ${data}/Pfalcon_TLR_contig.txt
cat ${data}/Pfalcon_TLR_contig.txt | parallel "samtools view -bh ${bam}/bFalPer1.pri_align_sorted.bam {} > {}.bam"
```

### BLAST Dependencies Explanation

```         
Step 1: makeblastdb
- in: reference genome of non-model species
- dbtype: nucleic acid (nucl) or protein (prot) sequences specified
- out: user determined file name for the output database created

Step 2: tblastn
- db: database created from the makeblastdb job
- query: functional genes identified from the KEGG database
- out: user determined file name for the output
- outfmt 6: blast iudentified output format 6. User has option to make their own format
- num_threads: dependent upon computing capacity, but providing a value can speed up the module running process
- evalue: specifies the number of hits of similar quality. Lower evalue means less hits but higher score. Higher evalue means more hits, but lower score.

Step 3:
```

#### Output Files

Many files will be created from this model.
Output names were identified in the slurm file, but a general list is detailed below.

-   A set of nine **\_genomeDB** files with multiple file formats will be created.

-   **blastn.out** file contains XXX.
    *This file will be needed for the manual annotation process in Geneious.*

-   **contig.txt** file contains a list of contigs that have been identified to have the functional genes of interest present.
    *This file will be needed for the manual annotation process in Geneious.*

-   A set of **.bam** files will be present.
    The number of **.bam** files will vary, but should align with the number of contigs identified in the **contig.txt** file.
    *These files will be needed for the manual annotation process in Geneious.*

# Subsetting

In the BLAST step, a set of **.bam** files were created for each contig that has been identified to contain the functional genes of interest.
Once ready, these files will be exported to the desktop and imported into Geneious.

Some of these files are can be incredibly large and if the home computer has limited storage and ram, subsetting the files can be helpful for saving space and computational power.
Review file sizes using `ls -lht` in the blast directory to determine which files need to be subset.

Samtools view will be used for subsetting and in this example, the goal file size of 250 mb.

In the example below, the original file was \~500 mb and the file was subset by 50% (0.05) to reduce the size to \~250 mb.
Generally, not all files require subsetting, but a loop could be created for this process as a learning challenge!

## Slurm script example

```         
# Load module:
module load samtools/1.14

# Sort paths:
HiSatSam=/scratch/username/tlr_mining/p_falcon/blast

#samtools
samtools view -s 0.50 -b NC_051190.1.bam > NC_051190.1_0.050_subset.bam
```

### Dependencies Explanations

```         
- s: is the amount to subset the bam file
- b: input bam file to be subset
- >: user determined name of the output subset bam file; it is recommended to detail the amount the file was subset by.
```

#### Output Files

A single subset.bam file should be created depending on the user determined output name.
Use `ls -lht` to confirm goal file size was met.

# Stringtie

Stringtie assembles RNA-sequencing reads to transcripts, and is run on the whole genome, not the output from the samtools view step.

## slurm script example

```         
# Load modules:
module load stringtie/2.1.4

# Sort paths
data=/scratch/username/tlr_mining/p_falcon/samtools

# Stringtie
stringtie -p 24 -o pfal_stringtie_out.gtf ${data}/bFalPer1.pri_align_sorted.bam
```

### Dependencies Explanation

```         
- p: number of processors
- o: output file name option
- input file: can be SAM, BAM, or CRAN rna-seq align and sorted file. This is created in the samtools step. 
```

#### Output File

A file with the ending **stringtie_out.gtf** will be present in the samtools directory.
*This file will be needed for the manual annotation process in Geneious.*

# Secure Copy Files

Now the genome has been mined and resulting files need to be securely transferred from the cluster to the home computer.
For this step, `scp` is recommended. Review the data download section for a `scp` use refresher.

The following files are to be transferred to the home computer:

-   stringtie directory

    -   stringtie_out.gtf file

-   blast directory

    -   All the .bam files.
        If files were subset, do not download the original file, just the subset file.

    -   contig.txt file

    -   blastn.out file
    

